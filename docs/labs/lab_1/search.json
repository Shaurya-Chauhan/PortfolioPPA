[
  {
    "objectID": "labs/lab_1/index.html",
    "href": "labs/lab_1/index.html",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the California Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "labs/lab_1/index.html#scenario",
    "href": "labs/lab_1/index.html#scenario",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the California Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "labs/lab_1/index.html#learning-objectives",
    "href": "labs/lab_1/index.html#learning-objectives",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "labs/lab_1/index.html#submission-instructions",
    "href": "labs/lab_1/index.html#submission-instructions",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "labs/lab_1/index.html#data-retrieval",
    "href": "labs/lab_1/index.html#data-retrieval",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\nca_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    total_pop = \"B01003_001\",\n    hshld_income = \"B19013_001\"\n  ),\n  state = \"CA\",\n  year = 2022,\n  output = \"wide\"\n)\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\nca_clean &lt;- ca_data %&gt;%\n  mutate(\n    county_name = str_replace(NAME, \" County, California$\", \"\")\n  )\n\n\n# Display the first few rows\nhead(ca_clean)\n\n# A tibble: 6 × 7\n  GEOID NAME       total_popE total_popM hshld_incomeE hshld_incomeM county_name\n  &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;      \n1 06001 Alameda C…    1663823         NA        122488          1231 Alameda    \n2 06003 Alpine Co…       1515        206        101125         17442 Alpine     \n3 06005 Amador Co…      40577         NA         74853          6048 Amador     \n4 06007 Butte Cou…     213605         NA         66085          2261 Butte      \n5 06009 Calaveras…      45674         NA         77526          3875 Calaveras  \n6 06011 Colusa Co…      21811         NA         69619          5745 Colusa"
  },
  {
    "objectID": "labs/lab_1/index.html#data-quality-assessment",
    "href": "labs/lab_1/index.html#data-quality-assessment",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\nca_reliability &lt;- ca_clean %&gt;%\n  mutate(\n    moe_percentage = round((hshld_incomeM / hshld_incomeE) * 100, 2),\n    \n    reliability = case_when(\n      moe_percentage &lt; 5 ~ \"High Confidence\",\n      moe_percentage &gt;= 5 & moe_percentage &lt;= 10 ~ \"Moderate\",\n      moe_percentage &gt; 10 ~ \"Low Confidence\"\n    )\n  )\n\n# Create a summary showing count of counties in each reliability category\n# Hint: use count() and mutate() to add percentages\nreliability_summary &lt;- ca_reliability %&gt;%\n  group_by(reliability) %&gt;%\n  summarize(\n    counties = n(),\n    avg_income = round(mean(hshld_incomeE, na.rm = TRUE), 0)\n  )"
  },
  {
    "objectID": "labs/lab_1/index.html#high-uncertainty-counties",
    "href": "labs/lab_1/index.html#high-uncertainty-counties",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\nhigh_uncertainty &lt;- ca_reliability %&gt;%\n  filter(moe_percentage &gt; 8) %&gt;%\n  arrange(desc(moe_percentage)) %&gt;%\n  slice_head(n = 5) %&gt;%\n  select(county_name, hshld_incomeE, moe_percentage, hshld_incomeM, reliability)\n\nglimpse(high_uncertainty)\n\nRows: 5\nColumns: 5\n$ county_name    &lt;chr&gt; \"Mono\", \"Alpine\", \"Sierra\", \"Trinity\", \"Plumas\"\n$ hshld_incomeE  &lt;dbl&gt; 82038, 101125, 61108, 47317, 67885\n$ moe_percentage &lt;dbl&gt; 18.76, 17.25, 15.12, 12.45, 11.45\n$ hshld_incomeM  &lt;dbl&gt; 15388, 17442, 9237, 5890, 7772\n$ reliability    &lt;chr&gt; \"Low Confidence\", \"Low Confidence\", \"Low Confidence\", \"…\n\n# Format as table with kable() - include appropriate column names and caption\nkable(high_uncertainty,\n      col.names = c(\"County\", \"Household Income\", \"MOE %\", \"MOE\", \"Reliability Category\"),\n      caption = \"Counties with Highest Income Data Uncertainty\",\n      format.args = list(big.mark = \",\"))\n\n\nCounties with Highest Income Data Uncertainty\n\n\nCounty\nHousehold Income\nMOE %\nMOE\nReliability Category\n\n\n\n\nMono\n82,038\n18.76\n15,388\nLow Confidence\n\n\nAlpine\n101,125\n17.25\n17,442\nLow Confidence\n\n\nSierra\n61,108\n15.12\n9,237\nLow Confidence\n\n\nTrinity\n47,317\n12.45\n5,890\nLow Confidence\n\n\nPlumas\n67,885\n11.45\n7,772\nLow Confidence\n\n\n\n\n\nData Quality Commentary:\nMargin of Error is high so Reliability is low. Therefore, decision making for authorities becomes challenging as this data does not have enough specificity for policy makers to be able to make specific decisions. Thos higher uncertainty might be related to adjustments made to account for households that didnt respond or since the data is representative, weighting is done for the data which might compound any variations in data"
  },
  {
    "objectID": "labs/lab_1/index.html#focus-area-selection",
    "href": "labs/lab_1/index.html#focus-area-selection",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\nselected_counties &lt;- ca_reliability %&gt;%\n  group_by(reliability) %&gt;%\n  slice_sample(n = 1) %&gt;%\n  ungroup()\n\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\nselected_counties %&gt;%\n  select(county_name, hshld_incomeE, moe_percentage, reliability)\n\n# A tibble: 3 × 4\n  county_name hshld_incomeE moe_percentage reliability    \n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 Butte               66085           3.42 High Confidence\n2 Plumas              67885          11.4  Low Confidence \n3 San Benito         104451           5.23 Moderate       \n\n\nComment on the output: The population estimate for these counties is directly proportional to the reliability. Higher population county i.e. Santa Clara also has the most reliability while ALpine has the lowest population estimate number and also has least reliable household income data."
  },
  {
    "objectID": "labs/lab_1/index.html#tract-level-demographics",
    "href": "labs/lab_1/index.html#tract-level-demographics",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\n\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\nca_tract_data &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(\n    white_pop = \"B03002_003\",\n    black_pop = \"B03002_004\",\n    latino_pop = \"B03002_012\",\n    total_pop = \"B03002_001\"\n  ),\n  state = \"CA\",\n  year = 2022,\n  output = \"wide\"\n)\n\nca_tract_clean &lt;- ca_tract_data %&gt;%\n  mutate(\n    tract_name = str_replace(NAME, \"; California$\", \"\")\n  )\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\ntract_pop_percentages &lt;- ca_tract_clean %&gt;%\n  mutate(\n    pct_white    = round((white_popE / total_popE) * 100, 1),\n    pct_black    = round((black_popE / total_popE) * 100, 1),\n    pct_hispanic = round((latino_popE / total_popE) * 100, 1)\n  )\n\n# Add readable tract and county name columns using str_extract() or similar\ntract_pop_percentages &lt;- tract_pop_percentages %&gt;%\n  separate(NAME, \n           into = c(\"tract_name\", \"county_name\", \"state_name\"), \n           sep = \"; \")"
  },
  {
    "objectID": "labs/lab_1/index.html#demographic-analysis",
    "href": "labs/lab_1/index.html#demographic-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\nhighest_latino_pct &lt;- tract_pop_percentages %&gt;%\n  arrange(desc(pct_hispanic)) %&gt;%\n  slice_head(n = 1)\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\n county_averages &lt;- tract_pop_percentages %&gt;%\n  group_by(county_name) %&gt;%\n  summarize(\n    avg_white = round(mean(pct_white, na.rm = TRUE), 1),\n    avg_black = round(mean(pct_black, na.rm = TRUE), 1),\n    avg_hispanic = round(mean(pct_hispanic, na.rm = TRUE), 1),\n    total_tracts = n() # Bonus: see how many tracts are in each county\n  ) %&gt;%\n  ungroup()\n\n# Create a nicely formatted table of your results using kable()\nlibrary(kableExtra)\n county_averages %&gt;%\n  kable(\n    col.names = c(\"County\", \"% White\", \"% Black\", \"% Hispanic\", \"Total Tracts\"),\n    caption = \"Average Demographics by County\",\n    align = \"lrrr\"\n  )\n\n\nAverage Demographics by County\n\n\nCounty\n% White\n% Black\n% Hispanic\nTotal Tracts\n\n\n\n\nAlameda County\n31.0\n10.7\n21.4\n379\n\n\nAlpine County\n58.1\n0.0\n14.1\n1\n\n\nAmador County\n75.7\n1.6\n14.9\n10\n\n\nButte County\n69.3\n1.5\n17.4\n54\n\n\nCalaveras County\n81.0\n0.9\n11.6\n14\n\n\nColusa County\n34.0\n1.6\n60.4\n6\n\n\nContra Costa County\n42.6\n8.0\n25.1\n242\n\n\nDel Norte County\n59.5\n2.2\n19.6\n9\n\n\nEl Dorado County\n76.0\n0.6\n13.8\n55\n\n\nFresno County\n28.4\n4.1\n54.1\n225\n\n\nGlenn County\n54.0\n0.3\n39.2\n8\n\n\nHumboldt County\n72.1\n1.3\n11.6\n36\n\n\nImperial County\n11.4\n2.6\n82.3\n40\n\n\nInyo County\n62.1\n0.8\n23.2\n6\n\n\nKern County\n33.1\n4.7\n54.0\n236\n\n\nKings County\n29.6\n5.7\n57.3\n31\n\n\nLake County\n69.3\n2.5\n20.0\n21\n\n\nLassen County\n70.0\n5.0\n15.3\n9\n\n\nLos Angeles County\n26.3\n7.6\n47.6\n2498\n\n\nMadera County\n33.7\n2.4\n58.0\n34\n\n\nMarin County\n69.2\n2.5\n16.5\n63\n\n\nMariposa County\n76.8\n0.8\n13.4\n6\n\n\nMendocino County\n64.6\n0.5\n24.9\n24\n\n\nMerced County\n25.4\n2.8\n62.1\n63\n\n\nModoc County\n76.6\n1.4\n15.1\n4\n\n\nMono County\n64.2\n0.2\n27.8\n4\n\n\nMonterey County\n35.2\n2.0\n52.6\n104\n\n\nNapa County\n54.6\n2.1\n31.7\n40\n\n\nNevada County\n83.4\n0.3\n9.6\n26\n\n\nOrange County\n41.3\n1.5\n32.4\n614\n\n\nPlacer County\n70.9\n1.4\n14.5\n92\n\n\nPlumas County\n85.2\n0.6\n8.6\n7\n\n\nRiverside County\n34.6\n5.7\n49.9\n518\n\n\nSacramento County\n43.2\n9.1\n23.8\n363\n\n\nSan Benito County\n32.9\n0.8\n59.5\n12\n\n\nSan Bernardino County\n28.5\n7.1\n53.3\n466\n\n\nSan Diego County\n45.5\n4.4\n33.3\n737\n\n\nSan Francisco County\n39.5\n5.1\n15.1\n244\n\n\nSan Joaquin County\n29.8\n6.7\n43.6\n174\n\n\nSan Luis Obispo County\n67.1\n1.3\n23.2\n70\n\n\nSan Mateo County\n37.9\n2.1\n23.5\n174\n\n\nSanta Barbara County\n46.0\n1.8\n43.6\n109\n\n\nSanta Clara County\n29.6\n2.3\n25.3\n408\n\n\nSanta Cruz County\n56.7\n0.8\n34.2\n70\n\n\nShasta County\n77.7\n0.9\n10.6\n50\n\n\nSierra County\n86.6\n0.2\n11.4\n1\n\n\nSiskiyou County\n73.9\n1.2\n14.5\n16\n\n\nSolano County\n36.1\n13.0\n28.2\n100\n\n\nSonoma County\n63.6\n1.4\n25.6\n122\n\n\nStanislaus County\n38.7\n2.7\n48.9\n112\n\n\nSutter County\n45.8\n1.8\n32.5\n21\n\n\nTehama County\n65.9\n0.9\n26.0\n14\n\n\nTrinity County\n79.2\n1.8\n7.0\n4\n\n\nTulare County\n27.4\n1.2\n65.3\n103\n\n\nTuolumne County\n78.1\n1.9\n13.5\n18\n\n\nVentura County\n45.0\n1.7\n42.1\n190\n\n\nYolo County\n46.5\n2.7\n31.1\n53\n\n\nYuba County\n56.0\n3.2\n26.7\n19"
  },
  {
    "objectID": "labs/lab_1/index.html#moe-analysis-for-demographic-variables",
    "href": "labs/lab_1/index.html#moe-analysis-for-demographic-variables",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\nMOE_demographic &lt;- tract_pop_percentages %&gt;%\n  mutate(\n    moe_percentage_white = round((white_popM / white_popE) * 100, 2),\n    moe_percentage_black = round((black_popM / black_popE) * 100, 2),\n    moe_percentage_latino = round((latino_popM / latino_popE) * 100, 2),\n    moe_percentage_popln_total = round((total_popM / total_popE) * 100, 2),\n    \n    reliability = case_when(\n      moe_percentage_popln_total &lt; 5 ~ \"High Confidence\",\n      moe_percentage_popln_total &gt;= 5 & moe_percentage_popln_total &lt;= 12 ~ \"Moderate Confidence\",\n      moe_percentage_popln_total &gt; 12 ~ \"Low Confidence\",\n      TRUE ~ \"No Data\"\n    )\n  )\n\n\n\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\nMOE_demographic &lt;- MOE_demographic %&gt;%\n  mutate(\n    high_moe_flag = case_when(\n      # Handle cases where population is zero (prevents 100% unreliability)\n      (white_popE == 0 & black_popE == 0 & latino_popE == 0) ~ \"No Population\",\n      \n      # The strict \"OR\" logic based on your assigned cutoffs\n      (moe_percentage_white &gt; 12 | \n       moe_percentage_black &gt; 12 | \n       moe_percentage_latino &gt; 12) ~ \"Unreliable Demographics\",\n      \n      # If it passes both above, it's reliable\n      TRUE ~ \"Reliable Demographics\"\n    )\n  )\n\n# Create summary statistics showing how many tracts have data quality issues\nquality_summary &lt;- MOE_demographic %&gt;%\n  count(high_moe_flag) %&gt;%\n  mutate(percentage = round((n / sum(n)) * 100, 1))"
  },
  {
    "objectID": "labs/lab_1/index.html#pattern-analysis",
    "href": "labs/lab_1/index.html#pattern-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\ndata_quality_pattern &lt;- MOE_demographic %&gt;%\n  group_by(high_moe_flag) %&gt;%\n  summarize(\n    count = n(),\n    avg_total_pop = mean(total_popE, na.rm = TRUE),\n    avg_white_pct = mean(pct_white, na.rm = TRUE),\n    avg_black_pct = mean(pct_black, na.rm = TRUE),\n    avg_latino_pct = mean(pct_hispanic, na.rm = TRUE)\n  ) %&gt;%\n  mutate(across(where(is.numeric), round, 1))\n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\npattern_table &lt;- data.frame(\n  `Quality Status` = c(\"Unreliable Demographics\", \"No Population\"),\n  `Avg Population` = c(4334, 2.6),\n  `Pct White` = c(38.0, 0),\n  `Pct Latino` = c(38.0, 0),\n  `Pct Black`  = c(5.3, 0)\n)\n\nkable(\n  pattern_table, \n  caption = \"Characteristics of Tracts with Data Quality Issues\",\n  align = \"lrrrr\",\n  col.names = c(\"Quality Status\", \"Avg Population\", \"% White\", \"% Latino\", \"% Black\")\n)\n\n\nCharacteristics of Tracts with Data Quality Issues\n\n\nQuality Status\nAvg Population\n% White\n% Latino\n% Black\n\n\n\n\nUnreliable Demographics\n4334.0\n38\n38\n5.3\n\n\nNo Population\n2.6\n0\n0\n0.0\n\n\n\n\n\nPattern Analysis: Data quality issues are mostly found in smaller neighborhoods where fewer people live- making the Census counts less certain. A major pattern is that when a specific group- like the Black population in this data- makes up a very small slice of the neighborhood (around 5.3%), the margin of error jumps too high to meet strict standards. We also see tracts with almost no people- which are likely parks or industrial areas rather than actual residential communities. This shows that it is very hard to get highly reliable data in places that are either sparsely populated or have very small numbers of a specific demographic group."
  },
  {
    "objectID": "labs/lab_1/index.html#analysis-integration-and-professional-summary",
    "href": "labs/lab_1/index.html#analysis-integration-and-professional-summary",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses? 2. Equity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings? 3. Root Cause Analysis: What underlying factors drive both data quality issues and bias risk? 4. Strategic Recommendations: What should the Department implement to address these systematic issues?\nExecutive Summary:\nAcross California, data reliability is following a clear systematic patter- accuracy is directly tied to population density and demographic concentration. At the county level, high-population hubs like Santa Clara exhibit high confidence while smaller rural areas like Alpine County show significant uncertainty in household income data. This pattern is even more pronounced at the tract level where neighborhoods with smaller total populations or very small distributions of specific demographic groups frequently fail to meet our reliability standards. Hence, the further the analysis zooms in into small sub-populations- the noisier and less reliable the census estimates become.\nThese findings present a significant equity risk- communities with the highest data uncertainty often face the greatest risk of algorithmic bias. Specifically, neighborhoods where the Black population makes up a small percentage (around 5.3% black in “unreliable” tracts) are disproportionately flagged as having low-confidence data. If an algorithmic system is used to prioritize social funding based on these metrics- these communities may be unfairly excluded or misrepresented. Under-represented or sparsely populated groups are almost hidden by high margins of error- which could lead to a systematic denial of resources to those who need them most.\nThe root cause of this reliability gap is sampling variability within the American Community Survey. Because the ACS is a sample rather than a full count- the margin of error increases as the sample size decreases. In tracts with lower residential density or areas with very small numbers of specific demographic groups, the noise in the data often exceeds our 12% reliability threshold. Also, almost 0 population tracts in non-residential industrial zones or parks can seemingly create mathematical errors that can further skew algorithm’s results.\nTo address these systematic issues- a tiered decision-making framework could perhaps be used. Algorithmic systems should only be used for immediate implementation in “High Confidence” counties where margins of error are below 5%. For “Moderate Confidence” areas, the Department could implement outcome monitoring to catch any potential biases. Finally, “Low Confidence” tracts or county must require a manual review or use proxy data sources —such as school enrollment or state tax records—before making any significant decisions."
  },
  {
    "objectID": "labs/lab_1/index.html#specific-recommendations",
    "href": "labs/lab_1/index.html#specific-recommendations",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\n\ncounty_recommendations &lt;- ca_reliability %&gt;%\n  mutate(\n    # Creating the decision framework\n    algorithm_recommendation = case_when(\n      reliability == \"High Confidence\" ~ \"Safe for algorithmic decisions\",\n      reliability == \"Moderate\" ~ \"Use with caution - monitor outcomes\",\n      reliability == \"Low Confidence\" ~ \"Requires manual review or additional data\",\n      TRUE ~ \"Data unavailable\"\n    )\n  ) %&gt;%\n  # Selecting and renaming columns for the final table\n  select(\n    `County` = county_name,\n    `Median Income` = hshld_incomeE,\n    `MOE %` = moe_percentage,\n    `Reliability Category` = reliability,\n    `Recommendation` = algorithm_recommendation\n  ) %&gt;%\n  # Sorting by MOE % to show most reliable data first\n  arrange(`MOE %`)\n\n\n\n# Format as a professional table with kable()\nkable(\n  county_recommendations,\n  caption = \"County-Level Algorithmic Implementation Framework\",\n  format.args = list(big.mark = \",\"),\n  align = \"lrrll\"\n)\n\n\nCounty-Level Algorithmic Implementation Framework\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMOE %\nReliability Category\nRecommendation\n\n\n\n\nLos Angeles\n83,411\n0.53\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOrange\n109,361\n0.81\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSacramento\n84,010\n0.97\nHigh Confidence\nSafe for algorithmic decisions\n\n\nAlameda\n122,488\n1.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Clara\n153,792\n1.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Diego\n96,974\n1.02\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Bernardino\n77,423\n1.04\nHigh Confidence\nSafe for algorithmic decisions\n\n\nContra Costa\n120,020\n1.25\nHigh Confidence\nSafe for algorithmic decisions\n\n\nRiverside\n84,505\n1.26\nHigh Confidence\nSafe for algorithmic decisions\n\n\nFresno\n67,756\n1.43\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Francisco\n136,689\n1.43\nHigh Confidence\nSafe for algorithmic decisions\n\n\nVentura\n102,141\n1.50\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlacer\n109,375\n1.70\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Joaquin\n82,837\n1.75\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Mateo\n149,907\n1.75\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSolano\n97,037\n1.78\nHigh Confidence\nSafe for algorithmic decisions\n\n\nStanislaus\n74,872\n1.83\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSonoma\n99,266\n2.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Barbara\n92,332\n2.05\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKern\n63,883\n2.07\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMonterey\n91,043\n2.09\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTulare\n64,474\n2.31\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Luis Obispo\n90,158\n2.56\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYolo\n85,097\n2.74\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNapa\n105,809\n2.82\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMarin\n142,019\n2.89\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Cruz\n104,409\n3.04\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKings\n68,540\n3.29\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMerced\n64,772\n3.31\nHigh Confidence\nSafe for algorithmic decisions\n\n\nEl Dorado\n99,246\n3.36\nHigh Confidence\nSafe for algorithmic decisions\n\n\nButte\n66,085\n3.42\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMendocino\n61,335\n3.58\nHigh Confidence\nSafe for algorithmic decisions\n\n\nShasta\n68,347\n3.63\nHigh Confidence\nSafe for algorithmic decisions\n\n\nHumboldt\n57,881\n3.68\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMadera\n73,543\n3.87\nHigh Confidence\nSafe for algorithmic decisions\n\n\nImperial\n53,847\n4.11\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYuba\n66,693\n4.19\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLake\n56,259\n4.34\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSutter\n72,654\n4.71\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNevada\n79,395\n4.82\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSiskiyou\n53,898\n4.90\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCalaveras\n77,526\n5.00\nModerate\nUse with caution - monitor outcomes\n\n\nSan Benito\n104,451\n5.23\nModerate\nUse with caution - monitor outcomes\n\n\nLassen\n59,515\n5.97\nModerate\nUse with caution - monitor outcomes\n\n\nGlenn\n64,033\n6.19\nModerate\nUse with caution - monitor outcomes\n\n\nTuolumne\n70,432\n6.66\nModerate\nUse with caution - monitor outcomes\n\n\nTehama\n59,029\n6.95\nModerate\nUse with caution - monitor outcomes\n\n\nDel Norte\n61,149\n7.16\nModerate\nUse with caution - monitor outcomes\n\n\nAmador\n74,853\n8.08\nModerate\nUse with caution - monitor outcomes\n\n\nColusa\n69,619\n8.25\nModerate\nUse with caution - monitor outcomes\n\n\nInyo\n63,417\n8.60\nModerate\nUse with caution - monitor outcomes\n\n\nMariposa\n60,021\n8.82\nModerate\nUse with caution - monitor outcomes\n\n\nModoc\n54,962\n9.80\nModerate\nUse with caution - monitor outcomes\n\n\nPlumas\n67,885\n11.45\nLow Confidence\nRequires manual review or additional data\n\n\nTrinity\n47,317\n12.45\nLow Confidence\nRequires manual review or additional data\n\n\nSierra\n61,108\n15.12\nLow Confidence\nRequires manual review or additional data\n\n\nAlpine\n101,125\n17.25\nLow Confidence\nRequires manual review or additional data\n\n\nMono\n82,038\n18.76\nLow Confidence\nRequires manual review or additional data\n\n\n\n\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: Counties: Santa Clara, Los Angeles, Sacramento, etc. Why: These counties feature high population estimates, which correlate directly with higher data reliability and low Margins of Error (MOE &lt; 5%). Their large sample sizes ensure that algorithmic decisions are based on stable, statistically significant data points, minimizing the risk.\nCounties requiring additional oversight: Counties: Calaveras, San Benito, Lassen, etc. Monitoring Needed: For these areas, the department should implement outcome monitoring- regularly auditing the algorithm’s decisions against real-world feedback to ensure that minor data fluctuations aren’t causing systematic biases.\nCounties needing alternative approaches: Counties: Plumas, Trinity, Sierra, etc. Because these areas often have small or sparsely distributed populations, the department should rely on manual review or supplemental data (such as local administrative records). Relying solely on a census-based algorithm here would likely lead to bias due to the high noise in the estimates."
  },
  {
    "objectID": "labs/lab_1/index.html#questions-for-further-investigation",
    "href": "labs/lab_1/index.html#questions-for-further-investigation",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n\nSpatial Correlation of Unreliability: Is there a geographic pattern to data unreliability? For e.g. are rural “border” tracts consistently more difficult to count than urban centers- regardless of the total population size?\nImpact of Time on Minority Margin of Error: How have the Margins of Error for small demographic subgroups (like the 5.3% Black population observed) changed over the last three ACS 5-year cycles? Is it becoming more or less reliable with time for such vulnerable groups?"
  },
  {
    "objectID": "labs/lab_1/index.html#submission-checklist",
    "href": "labs/lab_1/index.html#submission-checklist",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/labs/lab_1/your_file_name.html"
  }
]